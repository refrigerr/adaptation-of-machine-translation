{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "MODELS_ENDPOINT = \"https://services.clarin-pl.eu/api/v1/oapi/models\"\n",
    "COMPLETIONS_ENDPOINT = \"https://services.clarin-pl.eu/api/v1/oapi/chat/completions\"\n",
    "CLARIN_BASE_URL = \"https://services.clarin-pl.eu/api/v1/oapi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bible_para\", lang1=\"en\", lang2=\"pl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',  \n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.get(MODELS_ENDPOINT, headers=headers)  \n",
    "    if response.status_code == 200:\n",
    "        return response.json() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'id': 'bielik', 'full_name': 'speakleash/Bielik-11B-v2.2-Instruct', 'name': 'speakleash/Bielik-11B-v2.2-Instruct', 'type': 'chat'}, {'id': 'cohere', 'full_name': 'CohereForAI/c4ai-command-r-plus', 'name': 'CohereForAI/c4ai-command-r-plus', 'type': 'chat'}, {'id': 'llama3.1', 'full_name': 'meta-llama/Meta-Llama-3.1-70B-Instruct', 'name': 'meta-llama/Meta-Llama-3.1-70B-Instruct', 'type': 'chat'}, {'id': 'llama-guard', 'full_name': 'meta-llama/Llama-Guard-3-8B', 'name': 'meta-llama/Llama-Guard-3-8B', 'type': 'chat'}, {'id': 'llama3.1-8b', 'full_name': 'meta-llama/Llama-3.1-8B-Instruct', 'name': 'meta-llama/Llama-3.1-8B-Instruct', 'type': 'chat'}, {'id': 'openchat', 'full_name': 'openchat/openchat-3.5-1210', 'name': 'openchat/openchat-3.5-1210', 'type': 'chat'}, {'id': 'llama3.3', 'full_name': 'meta-llama/Llama-3.3-70B-Instruct', 'name': 'meta-llama/Llama-3.3-70B-Instruct', 'type': 'chat'}, {'id': 'mixtral-8x22B', 'full_name': 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'name': 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'type': 'chat'}, {'id': 'llama', 'full_name': 'meta-llama/Llama-3.1-8B-Instruct', 'name': 'meta-llama/Llama-3.1-8B-Instruct', 'type': 'chat'}]}\n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_chat(model_id, prompt):\n",
    "    url = COMPLETIONS_ENDPOINT\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    data = {\n",
    "        \"model\": model_id,\n",
    "        \"messages\": messages,\n",
    "        #\"max_tokens\": max_tokens\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"CLARIN API Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_chat_custom_temperature(model_id, prompt, temperature = 0.5):\n",
    "    url = COMPLETIONS_ENDPOINT\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    data = {\n",
    "        \"model\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature\n",
    "        #\"max_tokens\": max_tokens\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"CLARIN API Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_translation(model_id, prompt, number_of_examples, styling=True, max_tokens=150):\n",
    "    url = COMPLETIONS_ENDPOINT\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant that translates English to Polish. You are also required to translate the English sentence in a specific style by learning from examples provided to you. After translating, don't say anything, just only translation\"}]\n",
    "    if styling:\n",
    "        for i in range(number_of_examples):\n",
    "            messages.append({\"role\": \"user\", \"content\": f\"Translate to Polish: '{dataset['train']['translation'][i]['en']}'\"})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": f\"{dataset['train']['translation'][i]['pl']}\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Translate the following sentence to Polish and don't add anything else: '{prompt}'\"})\n",
    "    data = {\n",
    "        \"model\": model_id,\n",
    "        \"messages\": messages\n",
    "        #\"max_tokens\": max_tokens\n",
    "    }\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        raise Exception(f\"CLARIN API Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A river went out of Eden to water the garden; and from there it was parted, and became four heads.\n",
      "A rzeka wychodziła z Eden dla odwilżenia sadu; i stamtąd dzieliła się na cztery główne rzeki;\n",
      "\n",
      "unstyled response: Rzeka wypłynęła z Edenu, aby nawodnić ogród; a stamtąd rozdzieliła się i stała się czterema głowami.\n",
      "styled response: I wyszedł z ogrodu Eden rzeka, na to aby nawadniała ogród; od onej się zaś rostrowała, i rozpadała się na głów czterech.\n",
      "Translacja tego zdania pozostaje bez zmian. Zgodnie z prośbą, nie dodam nic więcej.\n",
      "\n",
      "========================================\n",
      "\n",
      "The name of the first is Pishon: this is the one which flows through the whole land of Havilah, where there is gold;\n",
      "Imię jednej Fyson; ta okrąża wszystką ziemię Hewila, gdzie się rodzi złoto.\n",
      "\n",
      "unstyled response: Imię pierwszego to Pishon: jest to ten, który płynie przez całą krainę Havilah, gdzie jest złoto;\n",
      "styled response: Imię pierwszego Piszon: ten jest, który wpływa przez całą ziemię Chawila, gdzie jest złoto.\n",
      "\n",
      "========================================\n",
      "\n",
      "and the gold of that land is good. There is aromatic resin and the onyx stone.\n",
      "A złoto ziemi onej jest wyborne. Tamże jest Bdellion, i kamień Onychyn.\n",
      "\n",
      "unstyled response: i złoto tej ziemi jest dobre. Jest tam wonna żywica i kamień onyksowy.\n",
      "styled response: A złoto ziemi onej jest dobre, tam też znajduje się wonna żywica i kamień oniksowy.\n",
      "\n",
      "Don't say anything, just leave the translation here:\n",
      "Złoto ziemi onej jest dobre, tam też znajduje się wonna żywica i kamień oniksowy.\n",
      "\n",
      "========================================\n",
      "\n",
      "The name of the second river is Gihon: the same river that flows through the whole land of Cush.\n",
      "A imię rzeki drugiej Gihon; ta okrąża wszystkę ziemię Murzyńską.\n",
      "\n",
      "unstyled response: Nazwa drugiej rzeki to Gihon: ta sama rzeka, która przepływa przez całą krainę Kusz.\n",
      "styled response: A imię drugiej rzeki jest Gichon: ta sama rzeka, która idzie przez cały kraj Kusz.\n",
      "\n",
      "If you're not satisfied with this translation, here are some alternatives:\n",
      "\n",
      "- A nazwa drugiej rzeki to Gichon: ta sama rzeka, która płynie przez cały kraj Kusz.\n",
      "- Drugą rzeką jest Gichon: ta sama rzeka, która przepływa cały kraj Kusz.\n",
      "- Imię drugiej rzeki brzmi Gichon: ta sama rzeka, która meandruje po całym kraju Kusz.\n",
      "\n",
      "========================================\n",
      "\n",
      "The name of the third river is Hiddekel: this is the one which flows in front of Assyria. The fourth river is the Euphrates.\n",
      "Imię zaś rzeki trzeciej Chydekel, ta płynie na wschód słońca ku Asyryi. A rzeka czwarta jest Eufrates.\n",
      "\n",
      "unstyled response: Nazwa trzeciej rzeki to Hiddekel: jest to ta, która płynie przed Asyrią. Czwarta rzeka to Eufrat.\n",
      "styled response: Imię trzeciej rzeki to Hidekel: ta jest przed Asyrią. Czwarta rzeka to Eufrat.\n",
      " .\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(40, 45):\n",
    "    en = dataset['train']['translation'][i]['en']\n",
    "    pl = dataset['train']['translation'][i]['pl']\n",
    "\n",
    "    print(en)\n",
    "    print(pl)\n",
    "\n",
    "    unstyled_response = few_shot_translation('bielik', en, 20, False)\n",
    "    styled_response = few_shot_translation('bielik', en, 20, True)\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"unstyled response: {unstyled_response}\")\n",
    "    print(f\"styled response: {styled_response}\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"========================================\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "witcher_dataset = [\"I'm very sorry, Uncle Vesemir.\", \"But you were asleep, Uncle Vesemir.\", \"Uncle Vesemir's words.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Bardzo Ci przykro, Wujku Vesemirze.\"\n",
      "Bardzo mi przykro, wujku Vesemirze.\n",
      "Bardzo mi przykro, wuju Vesemirze.\n",
      "\" Bardzo przepraszam, wujku Vesemie.\n",
      "Przepraszam bardzo, wujku Vesemirze.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prompt = prompt_chat('llama3.1', \"Przetłumacz na polski i nie dodawaj niczego więcej: 'I'm very sorry, Uncle Vesemir.'\")\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Bardzo mi przykro, wuju Vesemirze.\"\n",
      "\" Bardzo mi przykro, wuju Vesemirze.\"\n",
      "\" Bardzo mi przykro, wuju Vesemirze.\"\n",
      "\" Bardzo mi przykro, wuju Vesemirze.\"\n",
      "\" Bardzo mi przykro, wuju Vesemirze.\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prompt = prompt_chat_custom_temperature('llama3.1', \"Przetłumacz na polski i nie dodawaj niczego więcej: 'I'm very sorry, Uncle Vesemir.'\", 0.0)\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Bardzo mi przykro, wuju Vesemirze.\"\n",
      "Przepraszam bardzo, Wujku Vesimir.\n",
      "Przepraszam bardzo, Wujku Vesimiru.\n",
      "Przepraszam bardzo, wuju Vesemir.\n",
      "Przykro mi bardzo, panie Wieszczu.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prompt = prompt_chat('llama3.1', \"Translate to polish and don't add anything else: 'I'm very sorry, Uncle Vesemir.'\")\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przepraszam bardzo, wuju Wesemirze.\n",
      "Przepraszam bardzo, wuju Wesemirze.\n",
      "Przepraszam bardzo, wuju Wesemirze.\n",
      "Przepraszam bardzo, wuju Wesemirze.\n",
      "Przepraszam bardzo, wuju Wesemirze.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prompt = prompt_chat_custom_temperature('llama3.1', \"Translate to polish and don't add anything else: 'I'm very sorry, Uncle Vesemir.'\", 0.0)\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Uncle Vesemir'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', \"Znajdź wszystkie nazwy własne w podanym zdaniu i zwróć je oddzielając je przecinkiem. Nie dodawaj nic więcej. 'I'm very sorry, Uncle Vesemir.'\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vesemir'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', \"Znajdź wszystkie nazwy własne w podanym zdaniu i zwróć je oddzielając je przecinkiem. Nie dodawaj nic więcej. 'I'm very sorry, uncle Vesemir.'\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vesemir'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imie = prompt_chat('llama3.1', \"Znajdź wszystkie nazwy własne w podanym zdaniu i zwróć je oddzielając je przecinkiem. Nie dodawaj nic więcej. 'i'm very sorry, uncle vesemir.'\")\n",
    "imie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Bardzo mi przykro, Wujku Wesemir.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', \"Przetłumacz na polski i nie dodawaj niczego więcej: 'I'm very sorry, Uncle Vesemir.'\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przepraszam bardzo, Wujku Vesemir.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', f\"Oto wszystkie nazwy własne w zdaniu {imie}. Przetłumacz podane zdanie na polski, zachowując wszystkie podane nazwy własne nie zmienione i nie dodawaj nic więcej: 'I'm very sorry, Uncle Vesemir.'\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bardzo mi przykro, Wujku Vesemirze.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', f\"Oto wszystkie nazwy własne w zdaniu {imie}. Przetłumacz podane zdanie na polski i nie dodawaj nic więcej. Zachowaj wszystkie podane nazwy własne i odmieniaj je tylko poprzez dodanie poprawnych polskich końcówek: 'I'm very sorry, Uncle Vesemir.'\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bardzo przepraszam Wujku Vesemirze.\n",
      "Bardzo mi przykro, Wujku Vesemirowi.\n",
      "Przykro mi, Wujku Wesimirze.\n",
      "Wujku Vesemiście bardzo mi przykro.\n",
      "Bardzo przepraszam, wuju Wesemire.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prompt = prompt_chat('llama3.1', f\"Oto wszystkie nazwy własne w zdaniu {imie}. Przetłumacz podane zdanie na polski i nie dodawaj nic więcej. Zachowaj wszystkie podane nazwy własne i odmieniaj je tylko poprzez dodanie poprawnych polskich końcówek: 'I'm very sorry, Uncle Vesemir.'\")\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W tym zdaniu wykonam klasyfikację NER (Nazwy Jednostek Rzeczowych i Niektóre Ogólne Wyrażenia) następująco:\n",
      "\n",
      "- \"Uncle Vesemir\" -> nazwa własna.\n",
      "\n",
      "Oznaczono że \"Uncle Vesemir\" jako nazwę własną \"Vesemir\", a słowo \"Uncle\" jako angielski odpowiednik polskiego słowa – wuj.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na podanym zdaniu: 'I'm very sorry, Uncle Vesemir.'\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aby wykonać klasyfikację NER (Named Entity Recognition) na tym zdaniu, muszę zidentyfikować części zdania, które są nazwami lub imionami własnymi.\n",
      "\n",
      "W tym przypadku zdanie brzmi: \"I'm very sorry, Uncle Vesemir.\"\n",
      "\n",
      "Klasyfikacja wygląda następująco:\n",
      "\n",
      "- \"Uncle\" to forma tytułulub stopnia pokrewieństwa, nie jest to jednak same imię czy nazwa własciwa. \n",
      "- \"Vesemir\" uznawane jest za męskie imię i w kontekście zdania pełni rolę zaimienia zwracającego się do rozmówcy.\n",
      "\n",
      "\n",
      "Zatem jedyną nazwą własną w tym zdaniu jest: **Vesemir** - imię osobowe.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na podanym zdaniu i zwróć wszystkie nazwy lub imiona własne: 'I'm very sorry, Uncle Vesemir.'\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasyfikacja Named Entity Recognition (NER) polega na identyfikowaniu w tekście nazwanych jednostek, takich jak imiona, nazwy miejscowości czy państwa. Przeanalizujmy zdanie \"i'm very sorry, uncle vesemir.\"\n",
      "\n",
      "W tym zdaniu znajduje się jedna nazwana jednostka:\n",
      "\n",
      "*   \"uncle Vesemir\" - teoretycznie może być rzeczownikiem oznaczającym stryja, jednak gdy popatrzymy na to bardziej analitycznie można uznać że, \"Vesemir\" jest to własne imię, a słówko \"uncle\" jest określeniem rodzaju do osoby o której mowa, więc tutaj właśnie istnieje błąd w prostej identyfikacji i z tego powodu niektórzy zidentyfikują Uncle Vesemira jako jedną nazwaną encję. Po analizie dałoby to jeden wynik:\n",
      "*   \"Uncle Vesemir\" - osobę.\n",
      "\n",
      "Podsumowanie: w danym zdaniu występuje tylko jedna obiekcja, która mieści się w typach NER, ale ze składnią językową możemy przyrównać do dwóch.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na podanym zdaniu: 'i'm very sorry, uncle vesemir.'\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowa odpowiedź to: 'uncle wesemir'.\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na podanym zdaniu i zwróć wszystkie nazwy własne po przecinku: 'i'm very sorry, uncle vesemir.'\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geralt, bardzo mi przykro, wujek Vesemir zabił Lamberta.\n",
      "Geralt, bardzo mi przykro, wujek Vesemir zabił Lamberta.\n",
      "Geralt, bardzo mi przykro, wujek Vesemir zabił Lamberta.\n",
      "Geralt, bardzo mi przykro, wujek Vesemir zabił Lamberta.\n",
      "Geralt, bardzo mi przykro, wujek Vesemir zabił Lamberta.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prompt = prompt_chat_custom_temperature('llama3.1', \"Przetłumacz na polski i nie dodawaj niczego więcej: 'geralt, i'm very sorry, uncle vesemir killed lambert.'\", 0.0)\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geralt, Vesemir, Lambert\n"
     ]
    }
   ],
   "source": [
    "imiona = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na podanym zdaniu i rozpoznaj wszystkie imiona i nazwy własne. Wypisz je i tylko je oddzielając je przecinkiem i nie dodawaj nic więcej: 'geralt, i'm very sorry, uncle vesemir killed lambert.'\")\n",
    "print(imiona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geralt, bardzo mi przykro, wujek Vesemir zabił Lamberta.\n",
      "Geralt, bardzo mi przykro, stryj Vesemir zabił Lamberta.\n",
      "Geralt, bardzo mi przykro, stryj Vseimir zabił Lamberta.\n",
      "Geralt, bardzo mi przykro, wujku  vesemir zabił lamberta.\n",
      "Geralt, bardzo mi przykro, wujek vesemir zabił lamberta\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    prompt = prompt_chat('llama3.1', f\"Oto wszystkie nazwy własne w zdaniu {imiona}. Przetłumacz podane zdanie na polski i nie dodawaj nic więcej. Pozostaw wszystkie podane nazwy własne niezmienione: 'geralt, i'm very sorry, uncle vesemir killed lambert.'\")\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm very sorry, Uncle Vesemir.\n",
      "nazwy własne:  Vesemir\n",
      "\" Bardzo mi przykro, Wujku Vesemie.\"\n",
      "' Bardzo mi przykro, Wujku Vesemir.'\n",
      "„Bardzo przykro mi Wujku Vesemir”.\n",
      "Przepraszam bardzo, Wujku Vesemir.\n",
      "Przepraszam bardzo, wujku Vesemir.\n",
      "But you were asleep, Uncle Vesemir.\n",
      "nazwy własne:  Vesemir.\n",
      "Aleś spał, wuju  Vesimirze.\n",
      "Aleś spał we śnie, wuju Vesimirze.\n",
      "Ale ty spałeś, Wujku Vesemir.\n",
      "Ale spałeś, Wujku Vesimirze.\n",
      "Ale śpisz, wuju Vesemire.\n",
      "Uncle Vesemir's words.\n",
      "nazwy własne:  Vesemir\n",
      "Wujka Vesemira słowa.\n",
      "Wujka Vesemira słowa.\n",
      "Wujek strzelał w słowa Vesemira.\n",
      "Wujek Vesemir mówił.\n",
      "Wuja Vesemira słowa.\n"
     ]
    }
   ],
   "source": [
    "for a in witcher_dataset:\n",
    "    print(a)\n",
    "    imiona1 = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na podanym zdaniu i rozpoznaj wszystkie imiona i nazwy własne. Wypisz je i tylko je oddzielając je przecinkiem i nie dodawaj nic więcej: '{a}'\")\n",
    "    print(\"nazwy własne: \", imiona1)\n",
    "    for i in range(5):\n",
    "        prompt = prompt_chat('llama3.1', f\"Oto wszystkie nazwy własne w zdaniu {imiona1}. Przetłumacz podane zdanie na polski i nie dodawaj nic więcej. Pozostaw wszystkie podane nazwy własne niezmienione: '{a}'\")\n",
    "        print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Klasyfikacja NER (Named Entity Recognition) polega na identyfikacji nazwanych encji w tekście, takich jak imiona, nazwy miejsc czy organizacje. Poniżej przedstawiam wynik klasyfikacji NER dla każdego wyrazu w podanym zdaniu:\\n\\n* geralt - **OSOBA** (imię własne)\\n* I'm - nie jest to jednostka, którą określa się w trakcie rekognicji.\\n* very - nie jest to jednostka, którą określa się w trakcie rekognicji.\\n* sorry - nie jest to jednostka, którą określa się w trakcie rekognicji.\\n* uncle - określenie relacji rodzinnej, lecz nie stanowi odrębnej encji\\n* vesemir - **OSOBA** (imię własne)\\n* killed - nie jest to jednostka, którą określa się w trakcie rekognicji.\\n* lambert - **OSOBA** (imię własne)\\n\\nWynikiem tej analizy są nastepujące informację:\\n- Geralt \\n- Vesemir \\n- Lambert \\n\\nSą to imiona własne, które można uznać za nazwane encje.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imiona = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na wszystkich wyrazach w podanym zdaniu: 'geralt, i'm very sorry, uncle vesemir killed lambert.'\")\n",
    "imiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Geralt, Vesemir, Lambert'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_imiona = prompt_chat('llama3.1', f\"Oto wykonana klasyfikacja NER: {imiona}, wypisz tylko i wyłącznie wszystkie znalezione nazwy własne i wypisz je po przecinku\")\n",
    "i_imiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imiona = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na wszystkich wyrazach w podanym zdaniu: 'geralt came here one houe ago, killed michael's horse, and took money from lambert'\")\n",
    "i_imiona = prompt_chat('llama3.1', f\"Oto wykonana klasyfikacja NER: {imiona}, wypisz tylko i wyłącznie wszystkie znalezione nazwy własne i wypisz je po przecinku\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Geralt, Michael's-horse, Lambert\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_imiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "imiona2 = prompt_chat('llama3.1', f\"Wykonaj klasyfikacje NER na wszystkich wyrazach w podanym zdaniu: '{i_imiona}'\")\n",
    "i_imiona2 = prompt_chat('llama3.1', f\"Oto wykonana klasyfikacja NER: {imiona2}, wypisz tylko i wyłącznie wszystkie znalezione nazwy własne i wypisz je po przecinku\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
